{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding Social Intent from Neural Oscillations\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "**COGS 118C — Signal Processing Course Project**\n",
    "\n",
    "**Research Question:** Can we classify whether an animal is interacting socially vs. exploring alone based on the spectral features of its neural calcium signals?\n",
    "\n",
    "---\n",
    "\n",
    "### Goals of this notebook\n",
    "\n",
    "1. **Download & load** the three core datasets: calcium traces, behavioral labels, session metadata\n",
    "2. **Inspect** data shapes, sampling rates, and quality across all 18 sessions\n",
    "3. **Visualize** raw calcium signals with behavioral epoch overlays\n",
    "4. **Preliminary spectral analysis** — PSD, spectrograms, wavelets\n",
    "5. **Compare** spectral features between social vs. solo epochs\n",
    "6. **Sanity-check classification** with permutation test\n",
    "\n",
    "### Data sources\n",
    "\n",
    "| File | Format | Content |\n",
    "|------|--------|---------|\n",
    "| `calcium.00.h5` | HDF5 | 18 sessions of calcium traces (`C` key, frames x neurons), **30 fps** |\n",
    "| `social_bouts.00.h5` | HDF5 | 18 sessions of boolean behavioral labels, **25 fps** |\n",
    "| `SI3_2022_Entrance_Frames.xlsx` | Excel | Session metadata (animal, isolation condition, entry frame) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.signal import welch, butter, filtfilt, stft\n",
    "from scipy.stats import mannwhitneyu\n",
    "import pywt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='notebook', font_scale=1.1)\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "np.random.seed(42)\n",
    "print('All imports successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Download & Loading\n",
    "\n",
    "Three files from Google Drive, downloaded with `gdown`. The Drive file IDs were extracted from the EDGE source notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "DATA_DIR = Path('../data/raw')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = {\n",
    "    'calcium.00.h5':                 '1UthpsskvkHbKKDsbQjUxyVN4Xkd-ZJuN',   # ~250 MB\n",
    "    'social_bouts.00.h5':            '1Mh8oGKNyKpT5WS0Wu92SULFFanvqmSMf',   # ~510 KB\n",
    "    'SI3_2022_Entrance_Frames.xlsx': '1POpRqpA_QaWfZhxswQvLSs9uBnnHrmhZ',   # ~10 KB\n",
    "}\n",
    "\n",
    "for filename, file_id in FILES.items():\n",
    "    out_path = DATA_DIR / filename\n",
    "    if out_path.exists():\n",
    "        size_mb = out_path.stat().st_size / 1024 / 1024\n",
    "        print(f'  [skip] {filename} ({size_mb:.1f} MB)')\n",
    "    else:\n",
    "        print(f'  Downloading {filename}...')\n",
    "        gdown.download(f'https://drive.google.com/uc?id={file_id}', str(out_path), quiet=False)\n",
    "        size_mb = out_path.stat().st_size / 1024 / 1024\n",
    "        print(f'  [ok] {filename} ({size_mb:.1f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load session metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrances = pd.read_excel(DATA_DIR / 'SI3_2022_Entrance_Frames.xlsx')\n",
    "n_sessions = len(entrances)\n",
    "\n",
    "print(f'Sessions: {n_sessions}')\n",
    "print(f'Columns: {list(entrances.columns)}')\n",
    "print(f'\\nIsolation conditions:')\n",
    "print(entrances['Isolation Length'].value_counts().to_string())\n",
    "print()\n",
    "entrances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load behavioral labels (25 fps)\n",
    "\n",
    "Boolean arrays from `social_bouts.00.h5`. Each session group has:\n",
    "- `is_social` = any social interaction (sender OR receiver)\n",
    "- `is_social_sender` / `is_social_receiver` = directional\n",
    "- `is_ag_sniffed`, `is_ag_sniffing`, `is_of_sniffed`, `is_of_sniffing`, `is_touched`, `is_touching`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHAVIOR_FPS = 25\n",
    "\n",
    "behavior_keys = [\n",
    "    'is_ag_sniffed', 'is_ag_sniffing', 'is_of_sniffed', 'is_of_sniffing',\n",
    "    'is_social', 'is_social_receiver', 'is_social_sender',\n",
    "    'is_touched', 'is_touching',\n",
    "]\n",
    "\n",
    "behavior = []\n",
    "with h5py.File(DATA_DIR / 'social_bouts.00.h5', 'r') as f:\n",
    "    print(f'Top-level keys: {list(f.keys())}\\n')\n",
    "    for sess in range(n_sessions):\n",
    "        sd = {}\n",
    "        for key in behavior_keys:\n",
    "            sd[key] = f[f'session_{sess}'][key][:]\n",
    "        behavior.append(sd)\n",
    "        nf = len(sd['is_social'])\n",
    "        pct = sd['is_social'].mean() * 100\n",
    "        print(f'  Session {sess:2d}: {nf:6d} frames, '\n",
    "              f'{pct:5.1f}% social, '\n",
    "              f'isolation={entrances.iloc[sess][\"Isolation Length\"]}')\n",
    "\n",
    "print(f'\\nLoaded {len(behavior)} sessions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load calcium imaging data (30 fps)\n",
    "\n",
    "Each session has a `C` matrix of shape `(n_frames, n_neurons)` in `calcium.00.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGING_FPS = 30\n",
    "\n",
    "imaging = []\n",
    "with h5py.File(DATA_DIR / 'calcium.00.h5', 'r') as f:\n",
    "    print(f'Top-level keys: {list(f.keys())}\\n')\n",
    "    for sess in range(n_sessions):\n",
    "        C = f[f'session_{sess}']['C'][:]\n",
    "        imaging.append(C)\n",
    "        print(f'  Session {sess:2d}: C shape = {str(C.shape):>16s}  '\n",
    "              f'({C.shape[1]:3d} neurons, {C.shape[0]/IMAGING_FPS:.1f}s)')\n",
    "\n",
    "print(f'\\nLoaded {len(imaging)} sessions.')\n",
    "print(f'Imaging FPS: {IMAGING_FPS} | Nyquist: {IMAGING_FPS/2} Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Align behavior to imaging & crop to post-entry\n",
    "\n",
    "Behavior is at **25 fps**, imaging at **30 fps**. We:\n",
    "1. Convert the intruder entry frame from behavior fps to imaging fps\n",
    "2. Resample behavior labels (nearest-neighbor for boolean data)\n",
    "3. Crop both signals to start at the entry frame\n",
    "4. Trim to common length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_session(calcium_C, beh_dict, entry_beh, beh_fps, img_fps):\n",
    "    \"\"\"Align behavior labels to calcium imaging for one session.\"\"\"\n",
    "    entry_img = int(entry_beh * (img_fps / beh_fps))\n",
    "    if entry_img >= calcium_C.shape[0]:\n",
    "        return None, None\n",
    "\n",
    "    cal = calcium_C[entry_img:]\n",
    "    beh = beh_dict['is_social'][int(entry_beh):]\n",
    "\n",
    "    # Nearest-neighbor resample: beh_fps -> img_fps\n",
    "    n_beh = len(beh)\n",
    "    target = int(n_beh * (img_fps / beh_fps))\n",
    "    idx = np.round(np.linspace(0, n_beh - 1, target)).astype(int)\n",
    "    beh_rs = beh[idx]\n",
    "\n",
    "    common = min(len(cal), len(beh_rs))\n",
    "    return cal[:common], beh_rs[:common]\n",
    "\n",
    "\n",
    "aligned_calcium = []\n",
    "aligned_behavior = []\n",
    "session_info = []\n",
    "\n",
    "for i in range(n_sessions):\n",
    "    entry = int(entrances.iloc[i]['Int_Entry'])\n",
    "    cal, beh = align_session(imaging[i], behavior[i], entry, BEHAVIOR_FPS, IMAGING_FPS)\n",
    "    if cal is None:\n",
    "        print(f'  Session {i:2d}: SKIPPED')\n",
    "        continue\n",
    "\n",
    "    aligned_calcium.append(cal)\n",
    "    aligned_behavior.append(beh)\n",
    "    info = {\n",
    "        'session_idx': i,\n",
    "        'animal': entrances.iloc[i]['Animal'],\n",
    "        'isolation': entrances.iloc[i]['Isolation Length'],\n",
    "        'n_frames': len(cal),\n",
    "        'n_neurons': cal.shape[1],\n",
    "        'duration_s': len(cal) / IMAGING_FPS,\n",
    "        'social_frac': beh.mean(),\n",
    "    }\n",
    "    session_info.append(info)\n",
    "    print(f'  Session {i:2d}: {info[\"n_frames\"]:6d} frames, '\n",
    "          f'{info[\"n_neurons\"]:3d} neurons, '\n",
    "          f'{info[\"duration_s\"]:.0f}s, '\n",
    "          f'{info[\"social_frac\"]*100:.1f}% social, '\n",
    "          f'{info[\"isolation\"]}')\n",
    "\n",
    "session_df = pd.DataFrame(session_info)\n",
    "print(f'\\nAligned {len(aligned_calcium)} / {n_sessions} sessions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Quality & Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session_df.to_string(index=False))\n",
    "print(f'\\nTotal neurons: {session_df[\"n_neurons\"].sum()}')\n",
    "print(f'Total time: {session_df[\"duration_s\"].sum()/60:.1f} min')\n",
    "print(f'Mean social: {session_df[\"social_frac\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "iso_colors = {'GH (7d)': '#3498db', 'GH (24hr)': '#2ecc71',\n",
    "              '24hr': '#f39c12', '7d': '#e74c3c'}\n",
    "colors = session_df['isolation'].map(iso_colors).fillna('#95a5a6')\n",
    "\n",
    "axes[0].bar(range(len(session_df)), session_df['social_frac']*100, color=colors)\n",
    "axes[0].set_xlabel('Session'); axes[0].set_ylabel('% Social')\n",
    "axes[0].set_title('Social fraction per session')\n",
    "axes[0].axhline(50, color='gray', ls='--', lw=0.8)\n",
    "\n",
    "axes[1].bar(range(len(session_df)), session_df['n_neurons'], color=colors)\n",
    "axes[1].set_xlabel('Session'); axes[1].set_ylabel('Neurons')\n",
    "axes[1].set_title('Neuron count per session')\n",
    "\n",
    "for cond in session_df['isolation'].unique():\n",
    "    sub = session_df[session_df['isolation']==cond]\n",
    "    axes[2].scatter([cond]*len(sub), sub['social_frac']*100,\n",
    "                    s=80, alpha=0.7, color=iso_colors.get(cond, 'gray'))\n",
    "axes[2].set_ylabel('% Social')\n",
    "axes[2].set_title('Social fraction by isolation condition')\n",
    "axes[2].tick_params(axis='x', rotation=20)\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Calcium Signal Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick session closest to 30% social\n",
    "ex = session_df['social_frac'].sub(0.3).abs().idxmin()\n",
    "ex_cal = aligned_calcium[ex]\n",
    "ex_beh = aligned_behavior[ex]\n",
    "ex_info = session_info[ex]\n",
    "t = np.arange(len(ex_cal)) / IMAGING_FPS\n",
    "\n",
    "print(f'Example: session {ex_info[\"session_idx\"]} | '\n",
    "      f'{ex_info[\"n_neurons\"]} neurons | {ex_info[\"duration_s\"]:.0f}s | '\n",
    "      f'{ex_info[\"social_frac\"]*100:.1f}% social | {ex_info[\"isolation\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shade_social(ax, beh, t):\n",
    "    \"\"\"Red shading for social epochs.\"\"\"\n",
    "    mask = beh.astype(bool)\n",
    "    d = np.diff(mask.astype(int))\n",
    "    starts = np.where(d == 1)[0] + 1\n",
    "    ends = np.where(d == -1)[0] + 1\n",
    "    if mask[0]:  starts = np.concatenate([[0], starts])\n",
    "    if mask[-1]: ends = np.concatenate([ends, [len(mask)]])\n",
    "    for s, e in zip(starts, ends):\n",
    "        ax.axvspan(t[s], t[min(e, len(t)-1)], alpha=0.15, color='#e74c3c')\n",
    "\n",
    "\n",
    "n_show = 8\n",
    "top_neurons = np.argsort(ex_cal.std(axis=0))[-n_show:][::-1]\n",
    "\n",
    "fig, axes = plt.subplots(n_show+1, 1, figsize=(18, 2.2*(n_show+1)),\n",
    "                         sharex=True,\n",
    "                         gridspec_kw={'height_ratios': [1]*n_show + [0.5]})\n",
    "\n",
    "for i, ni in enumerate(top_neurons):\n",
    "    axes[i].plot(t, ex_cal[:, ni], lw=0.4, color='#2c3e50')\n",
    "    shade_social(axes[i], ex_beh, t)\n",
    "    axes[i].set_ylabel(f'N{ni}', fontsize=9)\n",
    "    axes[i].tick_params(labelsize=8)\n",
    "\n",
    "axes[-1].fill_between(t, ex_beh.astype(float), step='pre', alpha=0.7, color='#e74c3c')\n",
    "axes[-1].set_yticks([0,1]); axes[-1].set_yticklabels(['Solo','Social'])\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "axes[0].set_title(f'Session {ex_info[\"session_idx\"]} | Top {n_show} neurons (red=social)', fontsize=12)\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Calcium stats (session {ex_info[\"session_idx\"]}):\\n')\n",
    "print(f'  Shape:   {ex_cal.shape} (frames x neurons)')\n",
    "print(f'  Mean:    {ex_cal.mean():.4f}')\n",
    "print(f'  Std:     {ex_cal.std():.4f}')\n",
    "print(f'  Range:   [{ex_cal.min():.4f}, {ex_cal.max():.4f}]')\n",
    "print(f'  Nyquist: {IMAGING_FPS/2} Hz')\n",
    "\n",
    "stds = ex_cal.std(axis=0)\n",
    "print(f'\\nPer-neuron std: [{stds.min():.4f}, {stds.max():.4f}]')\n",
    "print(f'Low-activity (std < median/5): {(stds < np.median(stds)/5).sum()}/{ex_cal.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "axes[0].hist(ex_cal.ravel(), bins=100, color='#3498db', alpha=0.7, edgecolor='white')\n",
    "axes[0].set_xlabel('Calcium (a.u.)'); axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of calcium values')\n",
    "\n",
    "axes[1].bar(range(len(stds)), np.sort(stds)[::-1], color='#2ecc71', width=1)\n",
    "axes[1].set_xlabel('Neuron (sorted)'); axes[1].set_ylabel('Std')\n",
    "axes[1].set_title('Activity level per neuron')\n",
    "\n",
    "nc = min(30, ex_cal.shape[1])\n",
    "corr = np.corrcoef(ex_cal[:, :nc].T)\n",
    "im = axes[2].imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "axes[2].set_xlabel('Neuron'); axes[2].set_ylabel('Neuron')\n",
    "axes[2].set_title(f'Pairwise correlation (first {nc})')\n",
    "plt.colorbar(im, ax=axes[2], shrink=0.8)\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Photobleaching check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_trace = ex_cal.mean(axis=1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "axes[0].plot(t, mean_trace, lw=0.8, color='#2c3e50')\n",
    "slope, intercept = np.polyfit(t, mean_trace, 1)\n",
    "axes[0].plot(t, slope*t + intercept, '--r', lw=1.5, label=f'slope={slope:.2e}/s')\n",
    "axes[0].set_xlabel('Time (s)'); axes[0].set_ylabel('Mean calcium')\n",
    "axes[0].set_title('Population mean - photobleaching check'); axes[0].legend()\n",
    "\n",
    "win = int(30 * IMAGING_FPS)\n",
    "rolling = pd.Series(mean_trace).rolling(window=win, center=True).mean()\n",
    "axes[1].plot(t, rolling, lw=1.2, color='#e74c3c')\n",
    "shade_social(axes[1], ex_beh, t)\n",
    "axes[1].set_xlabel('Time (s)'); axes[1].set_ylabel('30s rolling mean')\n",
    "axes[1].set_title('Slow baseline drift (red=social)')\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "if abs(slope) > 1e-5:\n",
    "    print(f'Baseline drift detected (slope={slope:.2e}/s). Detrending recommended.')\n",
    "else:\n",
    "    print('No significant baseline drift.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Behavioral Epoch Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_durations(labels, fps):\n",
    "    d = np.diff(labels.astype(int))\n",
    "    bounds = np.where(d != 0)[0] + 1\n",
    "    starts = np.concatenate([[0], bounds])\n",
    "    ends = np.concatenate([bounds, [len(labels)]])\n",
    "    labs = np.array([labels[s] for s in starts])\n",
    "    durs = (ends - starts) / fps\n",
    "    return starts, ends, labs, durs\n",
    "\n",
    "_, _, ep_labs, ep_durs = get_epoch_durations(ex_beh, IMAGING_FPS)\n",
    "soc_d = ep_durs[ep_labs == 1]\n",
    "sol_d = ep_durs[ep_labs == 0]\n",
    "\n",
    "print(f'Session {ex_info[\"session_idx\"]}:')\n",
    "print(f'  Epochs: {len(ep_durs)}')\n",
    "print(f'  Social: {len(soc_d)}, mean={soc_d.mean():.2f}s, range=[{soc_d.min():.2f}, {soc_d.max():.2f}]')\n",
    "print(f'  Solo:   {len(sol_d)}, mean={sol_d.mean():.2f}s, range=[{sol_d.min():.2f}, {sol_d.max():.2f}]')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "sf = ex_beh.mean()\n",
    "axes[0].pie([sf, 1-sf], labels=['Social','Solo'],\n",
    "            colors=['#e74c3c','#3498db'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Class balance')\n",
    "\n",
    "mx = min(np.percentile(ep_durs, 95), 10)\n",
    "bins = np.linspace(0, mx, 30)\n",
    "axes[1].hist(soc_d[soc_d<mx], bins=bins, alpha=.7, color='#e74c3c', label='Social')\n",
    "axes[1].hist(sol_d[sol_d<mx], bins=bins, alpha=.7, color='#3498db', label='Solo')\n",
    "axes[1].set_xlabel('Duration (s)'); axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Epoch duration distribution'); axes[1].legend()\n",
    "\n",
    "show = min(len(ex_beh), int(120*IMAGING_FPS))\n",
    "axes[2].fill_between(t[:show], ex_beh[:show].astype(float),\n",
    "                     step='pre', alpha=.7, color='#e74c3c')\n",
    "axes[2].set_xlabel('Time (s)'); axes[2].set_yticks([0,1])\n",
    "axes[2].set_yticklabels(['Solo','Social'])\n",
    "axes[2].set_title('Timeline (first 120s)')\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Preliminary Spectral Analysis\n",
    "\n",
    "At 30 fps, Nyquist = 15 Hz. Frequency bands:\n",
    "- **Infraslow** 0.01-0.1 Hz | **Slow** 0.1-1 Hz | **Delta** 1-4 Hz | **Theta** 4-7 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_BANDS = {'infraslow': (0.01, 0.1), 'slow': (0.1, 1.0),\n",
    "              'delta': (1.0, 4.0), 'theta': (4.0, 7.0)}\n",
    "BAND_COLORS = {'infraslow': '#f39c12', 'slow': '#2ecc71',\n",
    "               'delta': '#3498db', 'theta': '#9b59b6'}\n",
    "\n",
    "print(f'fs={IMAGING_FPS} Hz, Nyquist={IMAGING_FPS/2} Hz')\n",
    "for n,(lo,hi) in FREQ_BANDS.items():\n",
    "    print(f'  {n:12s}: {lo}-{hi} Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Welch PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = int(10 * IMAGING_FPS)  # 10s windows\n",
    "noverlap = nperseg // 2\n",
    "nfft = max(1024, nperseg * 2)\n",
    "\n",
    "print(f'Window: {nperseg/IMAGING_FPS:.0f}s, Overlap: 50%, FFT: {nfft}, '\n",
    "      f'Resolution: {IMAGING_FPS/nperseg:.3f} Hz')\n",
    "\n",
    "f_w, psd_all = welch(ex_cal.T, fs=IMAGING_FPS,\n",
    "                     nperseg=nperseg, noverlap=noverlap, nfft=nfft, axis=1)\n",
    "print(f'PSD: {psd_all.shape} (neurons x freq)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpsd = psd_all.mean(axis=0)\n",
    "spsd = psd_all.std(axis=0) / np.sqrt(psd_all.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "for ax in axes:\n",
    "    for n,(lo,hi) in FREQ_BANDS.items():\n",
    "        ax.axvspan(lo, hi, alpha=0.1, color=BAND_COLORS[n], label=n)\n",
    "\n",
    "axes[0].plot(f_w, mpsd, color='#2c3e50', lw=1.5)\n",
    "axes[0].fill_between(f_w, mpsd-spsd, mpsd+spsd, alpha=.3, color='#3498db')\n",
    "axes[0].set_xlabel('Freq (Hz)'); axes[0].set_ylabel('PSD')\n",
    "axes[0].set_title('Mean PSD (linear)'); axes[0].legend(fontsize=8)\n",
    "\n",
    "axes[1].loglog(f_w[1:], mpsd[1:], color='#2c3e50', lw=1.5)\n",
    "axes[1].fill_between(f_w[1:], (mpsd-spsd)[1:], (mpsd+spsd)[1:], alpha=.3, color='#3498db')\n",
    "axes[1].set_xlabel('Freq (Hz)'); axes[1].set_ylabel('PSD')\n",
    "axes[1].set_title('Mean PSD (log-log)')\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "fm = f_w <= 10\n",
    "im = ax.imshow(10*np.log10(psd_all[:,fm]+1e-12), aspect='auto', cmap='viridis',\n",
    "               extent=[f_w[fm][0], f_w[fm][-1], psd_all.shape[0], 0])\n",
    "ax.set_xlabel('Freq (Hz)'); ax.set_ylabel('Neuron')\n",
    "ax.set_title('PSD heatmap (dB)')\n",
    "plt.colorbar(im, label='Power (dB)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Spectrogram (STFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_n = np.argmax(ex_cal.std(axis=0))\n",
    "sig = ex_cal[:, active_n]\n",
    "\n",
    "sn = int(5 * IMAGING_FPS)\n",
    "f_s, t_s, Zxx = stft(sig, fs=IMAGING_FPS, nperseg=sn, noverlap=sn//2)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(18, 10),\n",
    "                         gridspec_kw={'height_ratios': [1, 3, 0.5]})\n",
    "\n",
    "axes[0].plot(t, sig, lw=0.4, color='#2c3e50')\n",
    "shade_social(axes[0], ex_beh, t)\n",
    "axes[0].set_ylabel('Calcium')\n",
    "axes[0].set_title(f'Neuron {active_n} - STFT Spectrogram')\n",
    "\n",
    "fl = 10; fmask = f_s <= fl\n",
    "axes[1].pcolormesh(t_s, f_s[fmask], 10*np.log10(np.abs(Zxx[fmask])**2+1e-12),\n",
    "                   shading='gouraud', cmap='magma')\n",
    "axes[1].set_ylabel('Freq (Hz)')\n",
    "for _,(lo,hi) in FREQ_BANDS.items():\n",
    "    if hi<=fl: axes[1].axhline(lo, color='white', lw=0.5, alpha=0.4, ls='--')\n",
    "\n",
    "axes[2].fill_between(t, ex_beh.astype(float), step='pre', alpha=.7, color='#e74c3c')\n",
    "axes[2].set_yticks([0,1]); axes[2].set_yticklabels(['Solo','Social'])\n",
    "axes[2].set_xlabel('Time (s)')\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Morlet Wavelet Scalogram (60s segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = int(60 * IMAGING_FPS)\n",
    "ss, ts, bs = sig[:seg], t[:seg], ex_beh[:seg]\n",
    "\n",
    "freqs_want = np.linspace(0.5, 9, 50)\n",
    "wn = 'cmor1.5-1.0'\n",
    "scales = pywt.central_frequency(wn) * IMAGING_FPS / freqs_want\n",
    "\n",
    "print(f'CWT: 60s, {len(freqs_want)} freqs...')\n",
    "coeffs, freqs = pywt.cwt(ss, scales, wn, sampling_period=1/IMAGING_FPS)\n",
    "power = np.abs(coeffs)**2\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 8), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "axes[0].plot(ts, ss, lw=0.5, color='#2c3e50')\n",
    "shade_social(axes[0], bs, ts)\n",
    "axes[0].set_ylabel('Calcium')\n",
    "axes[0].set_title(f'Neuron {active_n} - Morlet CWT (60s)')\n",
    "\n",
    "axes[1].pcolormesh(ts, freqs, 10*np.log10(power+1e-12), shading='gouraud', cmap='magma')\n",
    "axes[1].set_ylabel('Freq (Hz)'); axes[1].set_xlabel('Time (s)')\n",
    "for _,(lo,hi) in FREQ_BANDS.items():\n",
    "    axes[1].axhline(lo, color='white', lw=0.5, alpha=0.4, ls='--')\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Social vs. Solo: Spectral Feature Comparison\n",
    "\n",
    "Extract features from 5-second windows within pure behavioral states across **all sessions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_features(segment, fs, bands):\n",
    "    \"\"\"Spectral features from a 1D signal.\"\"\"\n",
    "    nl = min(len(segment), int(5*fs))\n",
    "    f, psd = welch(segment, fs=fs, nperseg=nl, noverlap=nl//2)\n",
    "    ft = {}\n",
    "\n",
    "    for name,(lo,hi) in bands.items():\n",
    "        m = (f>=lo)&(f<hi)\n",
    "        ft[f'power_{name}'] = np.trapz(psd[m], f[m]) if m.sum()>0 else 0.0\n",
    "\n",
    "    tp = np.trapz(psd[f>0], f[f>0])\n",
    "    ft['total_power'] = tp\n",
    "    if tp > 0:\n",
    "        for name in bands:\n",
    "            ft[f'relpower_{name}'] = ft[f'power_{name}'] / tp\n",
    "\n",
    "    pn = psd[f>0] / (psd[f>0].sum()+1e-12)\n",
    "    pn = pn[pn>0]\n",
    "    ft['spectral_entropy'] = -np.sum(pn * np.log2(pn))\n",
    "    ft['peak_freq'] = f[np.argmax(psd)]\n",
    "\n",
    "    fp, pp = f[f>0], psd[f>0]\n",
    "    ft['spectral_centroid'] = np.sum(fp*pp) / (np.sum(pp)+1e-12)\n",
    "\n",
    "    cum = np.cumsum(pp)\n",
    "    if cum[-1]>0:\n",
    "        ei = np.searchsorted(cum, 0.9*cum[-1])\n",
    "        ft['spectral_edge_90'] = fp[min(ei, len(fp)-1)]\n",
    "\n",
    "    if ft.get('power_delta',0)>0:\n",
    "        ft['theta_delta_ratio'] = ft.get('power_theta',0) / ft['power_delta']\n",
    "\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_SEC = 5.0\n",
    "W_SAMP = int(W_SEC * IMAGING_FPS)\n",
    "PURITY = 0.9\n",
    "\n",
    "all_feat = []\n",
    "for si in tqdm(range(len(aligned_calcium)), desc='Sessions'):\n",
    "    cal = aligned_calcium[si]\n",
    "    beh = aligned_behavior[si]\n",
    "\n",
    "    for start in range(0, len(cal)-W_SAMP, W_SAMP):\n",
    "        end = start + W_SAMP\n",
    "        frac = beh[start:end].mean()\n",
    "        if frac > PURITY:       label = 1\n",
    "        elif frac < 1-PURITY:   label = 0\n",
    "        else:                   continue\n",
    "\n",
    "        pm = cal[start:end].mean(axis=1)\n",
    "        ft = spectral_features(pm, IMAGING_FPS, FREQ_BANDS)\n",
    "        ft['label'] = label\n",
    "        ft['session'] = si\n",
    "        ft['start_time'] = start / IMAGING_FPS\n",
    "        ft['isolation'] = session_info[si]['isolation']\n",
    "        all_feat.append(ft)\n",
    "\n",
    "df_feat = pd.DataFrame(all_feat)\n",
    "print(f'\\nWindows: {len(df_feat)} '\n",
    "      f'(social={(df_feat[\"label\"]==1).sum()}, solo={(df_feat[\"label\"]==0).sum()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = [f for f in ['power_delta','power_theta','spectral_entropy',\n",
    "      'spectral_centroid','theta_delta_ratio','total_power'] if f in df_feat.columns]\n",
    "\n",
    "fig, axes = plt.subplots(2, (len(pf)+1)//2, figsize=(18, 9))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feat in enumerate(pf):\n",
    "    soc = df_feat.loc[df_feat['label']==1, feat].dropna()\n",
    "    sol = df_feat.loc[df_feat['label']==0, feat].dropna()\n",
    "    axes[i].hist(sol, bins=30, alpha=.6, color='#3498db', label='Solo', density=True)\n",
    "    axes[i].hist(soc, bins=30, alpha=.6, color='#e74c3c', label='Social', density=True)\n",
    "    axes[i].set_title(feat, fontsize=11); axes[i].legend(fontsize=8)\n",
    "    _, pv = mannwhitneyu(soc, sol, alternative='two-sided')\n",
    "    sig = '***' if pv<.001 else '**' if pv<.01 else '*' if pv<.05 else 'ns'\n",
    "    axes[i].set_xlabel(f'p={pv:.2e} {sig}', fontsize=9)\n",
    "\n",
    "for j in range(len(pf), len(axes)): axes[j].set_visible(False)\n",
    "plt.suptitle('Spectral Features: Social vs Solo (all sessions)', fontsize=14, y=1.01)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean PSD: social vs solo\n",
    "soc_p, sol_p = [], []\n",
    "for si in range(len(aligned_calcium)):\n",
    "    cal=aligned_calcium[si]; beh=aligned_behavior[si]\n",
    "    for start in range(0, len(cal)-W_SAMP, W_SAMP):\n",
    "        end=start+W_SAMP; frac=beh[start:end].mean()\n",
    "        pm=cal[start:end].mean(axis=1)\n",
    "        nl=min(W_SAMP, int(5*IMAGING_FPS))\n",
    "        fs_, ps_ = welch(pm, fs=IMAGING_FPS, nperseg=nl, noverlap=nl//2)\n",
    "        if frac>PURITY: soc_p.append(ps_)\n",
    "        elif frac<1-PURITY: sol_p.append(ps_)\n",
    "\n",
    "soc_p=np.array(soc_p); sol_p=np.array(sol_p)\n",
    "sm,ss=soc_p.mean(0), soc_p.std(0)/np.sqrt(len(soc_p))\n",
    "om,os=sol_p.mean(0), sol_p.std(0)/np.sqrt(len(sol_p))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "axes[0].semilogy(fs_, sm, color='#e74c3c', lw=1.5, label=f'Social (n={len(soc_p)})')\n",
    "axes[0].fill_between(fs_, sm-ss, sm+ss, alpha=.3, color='#e74c3c')\n",
    "axes[0].semilogy(fs_, om, color='#3498db', lw=1.5, label=f'Solo (n={len(sol_p)})')\n",
    "axes[0].fill_between(fs_, om-os, om+os, alpha=.3, color='#3498db')\n",
    "for n,(lo,hi) in FREQ_BANDS.items(): axes[0].axvspan(lo,hi,alpha=.08,color=BAND_COLORS[n])\n",
    "axes[0].set_xlabel('Freq (Hz)'); axes[0].set_ylabel('PSD')\n",
    "axes[0].set_title('Mean PSD: Social vs Solo'); axes[0].legend()\n",
    "\n",
    "lr = np.log2(sm / (om+1e-12))\n",
    "axes[1].plot(fs_, lr, color='#2c3e50', lw=1.5)\n",
    "axes[1].axhline(0, color='gray', ls='--', lw=.8)\n",
    "for n,(lo,hi) in FREQ_BANDS.items(): axes[1].axvspan(lo,hi,alpha=.08,color=BAND_COLORS[n])\n",
    "axes[1].set_xlabel('Freq (Hz)'); axes[1].set_ylabel('log2(Social/Solo)')\n",
    "axes[1].set_title('PSD ratio (>0 = more power during social)')\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Classification Sanity Check\n",
    "\n",
    "**GroupKFold** with sessions as groups prevents cross-session data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ['label','session','start_time','isolation']\n",
    "fcols = [c for c in df_feat.columns if c not in meta]\n",
    "\n",
    "X = df_feat[fcols].fillna(0).values\n",
    "y = df_feat['label'].values\n",
    "groups = df_feat['session'].values\n",
    "\n",
    "Xs = np.nan_to_num(StandardScaler().fit_transform(X))\n",
    "ng = len(np.unique(groups))\n",
    "ns = min(5, ng)\n",
    "gkf = GroupKFold(n_splits=ns)\n",
    "\n",
    "clfs = {'LDA': LinearDiscriminantAnalysis(),\n",
    "        'SVM (linear)': SVC(kernel='linear', probability=True),\n",
    "        'Logistic Reg': LogisticRegression(max_iter=1000)}\n",
    "\n",
    "print(f'{ns}-fold GroupKFold (groups=sessions)')\n",
    "print(f'  Samples: {len(y)} (social={(y==1).sum()}, solo={(y==0).sum()})')\n",
    "print(f'  Features: {Xs.shape[1]}, Groups: {ng}')\n",
    "print('='*60)\n",
    "\n",
    "results = {}\n",
    "for name, clf in clfs.items():\n",
    "    accs, aucs = [], []\n",
    "    for tri, tei in gkf.split(Xs, y, groups):\n",
    "        ytr, yte = y[tri], y[tei]\n",
    "        if len(np.unique(ytr))<2 or len(np.unique(yte))<2: continue\n",
    "        clf.fit(Xs[tri], ytr)\n",
    "        accs.append(accuracy_score(yte, clf.predict(Xs[tei])))\n",
    "        aucs.append(roc_auc_score(yte, clf.predict_proba(Xs[tei])[:,1]))\n",
    "    results[name] = {'acc':np.mean(accs), 'acc_std':np.std(accs),\n",
    "                     'auc':np.mean(aucs), 'auc_std':np.std(aucs)}\n",
    "    print(f'\\n  {name}: Acc={np.mean(accs):.3f}+/-{np.std(accs):.3f}, '\n",
    "          f'AUC={np.mean(aucs):.3f}+/-{np.std(aucs):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test\n",
    "N_PERM = 200\n",
    "cp = LogisticRegression(max_iter=1000)\n",
    "pa = []\n",
    "\n",
    "for _ in tqdm(range(N_PERM), desc='Permutations'):\n",
    "    ys = np.random.permutation(y)\n",
    "    fa = []\n",
    "    for tri,tei in gkf.split(Xs, ys, groups):\n",
    "        ytr,yte = ys[tri], ys[tei]\n",
    "        if len(np.unique(ytr))<2 or len(np.unique(yte))<2: continue\n",
    "        cp.fit(Xs[tri], ytr)\n",
    "        fa.append(accuracy_score(yte, cp.predict(Xs[tei])))\n",
    "    if fa: pa.append(np.mean(fa))\n",
    "\n",
    "pa = np.array(pa)\n",
    "real = results['Logistic Reg']['acc']\n",
    "pval = np.mean(pa >= real)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.hist(pa, bins=30, color='#95a5a6', alpha=.7, label='Null')\n",
    "ax.axvline(real, color='#e74c3c', lw=2, ls='--', label=f'Real={real:.3f}')\n",
    "ax.set_xlabel('Accuracy'); ax.set_ylabel('Count')\n",
    "ax.set_title(f'Permutation test (p={pval:.4f})'); ax.legend()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print(f'Real: {real:.3f}, Chance: {pa.mean():.3f}+/-{pa.std():.3f}, p={pval:.4f}')\n",
    "print('SIGNIFICANT' if pval<0.05 else 'Not significant at p<0.05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary & Next Steps\n",
    "\n",
    "### Key findings (fill in after running)\n",
    "\n",
    "| Question | Finding |\n",
    "|----------|---------|\n",
    "| Sessions loaded | X / 18 aligned |\n",
    "| Neurons per session | range |\n",
    "| Class balance | X% social vs Y% solo |\n",
    "| Photobleaching | present / absent |\n",
    "| PSD structure | 1/f? band peaks? |\n",
    "| Social vs Solo PSD | differences in which bands? |\n",
    "| Classification | Acc X% (chance Y%, p=Z) |\n",
    "\n",
    "### Next steps\n",
    "\n",
    "1. **Preprocessing** — per-neuron detrending, z-scoring\n",
    "2. **Per-neuron features** — which neurons are most discriminative?\n",
    "3. **Isolation condition** — spectral signatures by GH / 24hr / 7d?\n",
    "4. **Wavelet features** — time-resolved spectral features from CWT\n",
    "5. **Movement confound** — SLEAP pose data could control for locomotion\n",
    "6. **Final pipeline** — optimized features, proper CV, publication figures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
